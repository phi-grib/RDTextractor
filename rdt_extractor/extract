#!/usr/bin/env python
#! -*- coding: utf-8 -*-

##    Description    eTOX repeat-dose toxicity extraction tool
##
##    Authors:       Elisabet Gregori (elisabet.gregori@upf.edu)
##                   Ignacio Pasamontes (ignacio.pasamontes@upf.edu)
##
##    Copyright 2018 Elisabet Gregori & Ignacio Pasamontes
##
##    RDTextractor is free software: you can redistribute it 
##    and/or modify it under the terms of the GNU General Public 
##    License as published by the Free Software Foundation version 3.
##
##    RDTextractor is distributed in the hope that it will be useful,
##    but WITHOUT ANY WARRANTY; without even the implied warranty of
##    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
##    GNU General Public License for more details.
##
##    You should have received a copy of the GNU General Public License
##    along with this code. If not, see <http://www.gnu.org/licenses/>.

import argparse, os, sys, time, math
import time
import pandas as pd
# Disable SettingWithCopyWarning warnings
pd.set_option('chained_assignment', None)
import cx_Oracle
import rdt_extractor

# Load ontology dataframe
onto_file = 'ontology.pkl'
packagedir = rdt_extractor.__path__[0]
fname = os.path.join(packagedir, '../data',  onto_file)
onto_df = pd.read_pickle(fname)

def load_version(args):

    """
    Load tables with information
    """

    if args.version == 'local':
        ########################## 
        # Load stored dataframes #
        ##########################

        # Load study dataframe
        study_file = 'study.pkl'
        fname = os.path.join(packagedir, '../data',  study_file)
        study_df = pd.read_pickle(fname)
        # Load finding dataframe
        find_file = 'findings.pkl.gz'
        fname = os.path.join(packagedir, '../data',  find_file)
        find_df = pd.read_pickle(fname, compression='gzip')
    else:
        #########################################
        # Query the Oracle database to generate #
        # the dataframes                        #
        #########################################

        #
        # Load normlisation lookup table
        #
        norm_file = 'normalisation.pkl'
        fname = os.path.join(packagedir, '../data',  norm_file)
        normD = pd.read_pickle(fname)

        dsn_tns = cx_Oracle.makedsn(args.host, args.port, args.sid)

        con = cx_Oracle.connect(args.user, args.passw, dsn_tns)
        cur = con.cursor()

        #
        # Compound information
        #
        cmd = "SELECT SUBST_ID, CASNO, COMMON_NAME, PHARMACOLOGICAL_ACTION, \
            STANDARDISED_TARGET, STANDARDISED_ACTION, COMPANY_ID, SMILES, STATUS \
            FROM SUBSTANCE_IDS \
	    JOIN PHARMACOLOGY ON PHARMACOLOGY.PARENT_LUID = SUBSTANCE_IDS.LUID"
        cur.execute(cmd)
        results = cur.fetchall()
        df = pd.DataFrame(results, columns=['subst_id', 'cas_number', 'common_name', 
                            'pharmacological_action', 'target', 'action', 'company_id', 
                            'smiles', 'status'])
        df.to_pickle('compound.pkl')

        sys.exit()


        #
        # Study information summary 
        #
        cmd = "SELECT STRUCTURE_LUID, PARENT_LUID, DOSE, STANDARDISED_SEX, NUMBER_OF_ANIMALS \
            FROM ANIMALS_PER_GROUP_PER_SEX"
        cur.execute(cmd)
        results = cur.fetchall()
        df = pd.DataFrame(results, columns=['subst_id', 'study_id', 'dose', 'sex', 'number_of_animals'])
        df.study_id = df.study_id.astype(object)
        df.to_pickle('animals_per_group_per_sex.pkl')

        #
        # Generate normalised study dataframe
        #
        sys.stdout.write('\tLoading studies\n')
        cmd = "SELECT STUDY_DESIGN.LUID, SUBST_ID, STANDARDISED_ROUTE, \
            STANDARDISED_SPECIES, STANDARDISED_STRAIN, EXPOSURE_PERIOD, REPORT_NUMBER \
            FROM STUDY_DESIGN \
            JOIN SUBSTANCE_IDS ON STUDY_DESIGN.STRUCTURE_LUID = SUBSTANCE_IDS.LUID"
        cur.execute(cmd)
        results = cur.fetchall()
        tmp_table = []
        for (study_id, subst_id, route, species, strain, exposure, report_number) in results:
             if route is None:
                 route = ''
             else:
                 route = route.upper()
                 route = normD[route]
             if species is None or species.upper() in ('EXCLUDED TERM'):
                 species = ''
             else:
                 species = species.upper()
                 species = normD[species]
             tmp_table.append([study_id, subst_id, route, species, 
                                exposure, report_number])
        study_df = pd.DataFrame(tmp_table, columns=['study_id', 'subst_id',
                        'normalised_administration_route', 'normalised_species', 'normalised_strain', 'exposure_period_days', 'report_number'])

        #
        # Generate normalised findings dataframe
        #
        sys.stdout.write('\tLoading findings\n')
        cmd = "SELECT DISTINCT PARENT_LUID AS study_id, RELEVANCE, \
            STANDARDISED_PATHOLOGY, STANDARDISED_ORGAN, \
            STANDARDISED_SEX, DOSE \
            FROM HISTOPATHOLOGICALFI \
            WHERE STANDARDISED_PATHOLOGY IS NOT NULL \
            AND STANDARDISED_ORGAN IS NOT NULL"
        cur.execute(cmd)
        results = cur.fetchall()
        tmp_table = []
        for (study_id, relevance, observation, parameter, sex, dose) in results:
            if observation is None or observation.upper() == 'EXCLUDED TERM':
                 observation = ''
            else:
                 observation_upper = observation.upper()
                 if observation_upper in normD:
                    observation = normD[observation_upper]
 
            if parameter is None or parameter.upper() == 'EXCLUDED TERM':
                parameter = ''
            else:
                parameter_upper = parameter.upper()
                if parameter_upper in normD:
                    parameter = normD[parameter_upper]

            if sex is None or sex.upper() == 'EXCLUDED TERM':
                sex = ''
            else:
                sex_upper = sex.upper()
                if sex_upper in normD:
                    sex = normD[sex_upper]
             
            if relevance is None:
                 relevance = 'NA'
            tmp_table.append([study_id, relevance, observation, parameter, sex, dose])

        find_df = pd.DataFrame(tmp_table, columns=['study_id', 'relevance',
                        'observation_normalised', 'organ_normalised',
                        'normalised_sex', 'dose'])
        find_df['endpoint_type'] = 'Histopathlogical finding'
        
        # cmd = "SELECT DISTINCT PARENT_LUID AS study_id, RELEVANCE, \
        #     FINDING, STANDARDISED_PARAMETER, \
        #     STANDARDISED_SEX, DOSE \
        #     FROM CLINICALCHEMICALFIN \
        #     WHERE FINDING IS NOT NULL \
        #     AND STANDARDISED_PARAMETER IS NOT NULL"
        # cur.execute(cmd)
        # results = cur.fetchall()
        # tmp_table = []
        # for (study_id, relevance, observation, parameter, sex, dose) in results:
        #     if observation is None or observation.upper() == 'EXCLUDED TERM':
        #          observation = ''
        #     else:
        #          observation_upper = observation.upper()
        #          if observation_upper in normD:
        #             observation = normD[observation_upper]
 
        #     if parameter is None or parameter.upper() == 'EXCLUDED TERM':
        #         parameter = ''
        #     else:
        #         parameter_upper = parameter.upper()
        #         if parameter_upper in normD:
        #             parameter = normD[parameter_upper]

        #     if sex is None or sex.upper() == 'EXCLUDED TERM':
        #         sex = ''
        #     else:
        #         sex_upper = sex.upper()
        #         if sex_upper in normD:
        #             sex = normD[sex_upper]
             
        #     if relevance is None:
        #          relevance = 'NA'
        #     tmp_table.append([study_id, relevance, observation, parameter, sex, dose])

        # tmp_df = pd.DataFrame(tmp_table, columns=['study_id', 'relevance',
        #                 'observation_normalised', 'organ_normalised',
        #                 'normalised_sex', 'dose'])
        # tmp_df['endpoint_type'] = 'Clinical chemical finding'
        # find_df = pd.concat[find_df, tmp_df]

        # cmd = "SELECT DISTINCT PARENT_LUID AS study_id, RELEVANCE, \
        #     FINDING, STANDARDISED_PARAMETER, \
        #     STANDARDISED_SEX, DOSE \
        #     FROM CLINICALHEMATOLOGIC \
        #     WHERE FINDING IS NOT NULL \
        #     AND STANDARDISED_PARAMETER IS NOT NULL"
        # cur.execute(cmd)
        # results = cur.fetchall()
        # tmp_table = []
        # for (study_id, relevance, observation, parameter, sex, dose) in results:
        #     if observation is None or observation.upper() == 'EXCLUDED TERM':
        #          observation = ''
        #     else:
        #          observation_upper = observation.upper()
        #          if observation_upper in normD:
        #             observation = normD[observation_upper]
 
        #     if parameter is None or parameter.upper() == 'EXCLUDED TERM':
        #         parameter = ''
        #     else:
        #         parameter_upper = parameter.upper()
        #         if parameter_upper in normD:
        #             parameter = normD[parameter_upper]

        #     if sex is None or sex.upper() == 'EXCLUDED TERM':
        #         sex = ''
        #     else:
        #         sex_upper = sex.upper()
        #         if sex_upper in normD:
        #             sex = normD[sex_upper]
             
        #     if relevance is None:
        #          relevance = 'NA'
        #     tmp_table.append([study_id, relevance, observation, parameter, sex, dose])

        # tmp_df = pd.DataFrame(tmp_table, columns=['study_id', 'relevance',
        #                 'observation_normalised', 'organ_normalised',
        #                 'normalised_sex', 'dose'])
        # tmp_df['endpoint_type'] = 'Clinical hematological finding'
        # find_df = pd.concat[find_df, tmp_df]

        # cmd = "SELECT DISTINCT PARENT_LUID AS study_id, RELEVANCE, \
        #     FINDING, STANDARDISED_ORGAN, \
        #     STANDARDISED_SEX, DOSE \
        #     FROM ORGAN_WEIGHTS \
        #     WHERE FINDING IS NOT NULL \
        #     AND STANDARDISED_ORGAN IS NOT NULL"
        # cur.execute(cmd)
        # results = cur.fetchall()
        # tmp_table = []
        # for (study_id, relevance, observation, parameter, sex, dose) in results:
        #     if observation is None or observation.upper() == 'EXCLUDED TERM':
        #          observation = ''
        #     else:
        #          observation_upper = observation.upper()
        #          if observation_upper in normD:
        #             observation = normD[observation_upper]
 
        #     if parameter is None or parameter.upper() == 'EXCLUDED TERM':
        #         parameter = ''
        #     else:
        #         parameter_upper = parameter.upper()
        #         if parameter_upper in normD:
        #             parameter = normD[parameter_upper]

        #     if sex is None or sex.upper() == 'EXCLUDED TERM':
        #         sex = ''
        #     else:
        #         sex_upper = sex.upper()
        #         if sex_upper in normD:
        #             sex = normD[sex_upper]
             
        #     if relevance is None:
        #          relevance = 'NA'
        #     tmp_table.append([study_id, relevance, observation, parameter, sex, dose])

        # tmp_df = pd.DataFrame(tmp_table, columns=['study_id', 'relevance',
        #                 'observation_normalised', 'organ_normalised',
        #                 'normalised_sex', 'dose'])
        # tmp_df['endpoint_type'] = 'Organ weight'
        # find_df = pd.concat[find_df, tmp_df]

        # cmd = "SELECT DISTINCT PARENT_LUID AS study_id, RELEVANCE, \
        #     STAND_CLINICAL_SIGN, STANDARDISED_SEX, DOSE \
        #     FROM CLINCAL_SIGNS \
        #     WHERE FINDING IS NOT NULL"
        # cur.execute(cmd)
        # results = cur.fetchall()
        # tmp_table = []
        # for (study_id, relevance, observation, sex, dose) in results:
        #     if observation is None or observation.upper() == 'EXCLUDED TERM':
        #          observation = ''
        #     else:
        #          observation_upper = observation.upper()
        #          if observation_upper in normD:
        #             observation = normD[observation_upper]

        #     if sex is None or sex.upper() == 'EXCLUDED TERM':
        #         sex = ''
        #     else:
        #         sex_upper = sex.upper()
        #         if sex_upper in normD:
        #             sex = normD[sex_upper]
             
        #     if relevance is None:
        #          relevance = 'NA'
        #     tmp_table.append([study_id, relevance, observation, sex, dose])

        # tmp_df = pd.DataFrame(tmp_table, columns=['study_id', 'relevance',
        #                 'observation_normalised', 'normalised_sex', 'dose'])
        # tmp_df['endpoint_type'] = 'Clinical signs'
        # find_df = pd.concat[find_df, tmp_df]

        # cmd = "SELECT DISTINCT PARENT_LUID AS study_id, RELEVANCE, \
        #     FINDING, STANDARDISED_PARAMETER, STANDARDISED_SEX, DOSE \
        #     FROM URINALYSIS_FINDINGS \
        #     WHERE FINDING IS NOT NULL"
        # cur.execute(cmd)
        # results = cur.fetchall()
        # tmp_table = []
        # for (study_id, relevance, observation, parameter, sex, dose) in results:
        #     if observation is None or observation.upper() == 'EXCLUDED TERM':
        #          observation = ''
        #     else:
        #          observation_upper = observation.upper()
        #          if observation_upper in normD:
        #             observation = normD[observation_upper]
 
        #     if parameter is None or parameter.upper() == 'EXCLUDED TERM':
        #         parameter = ''
        #     else:
        #         parameter_upper = parameter.upper()
        #         if parameter_upper in normD:
        #             parameter = normD[parameter_upper]

        #     if sex is None or sex.upper() == 'EXCLUDED TERM':
        #         sex = ''
        #     else:
        #         sex_upper = sex.upper()
        #         if sex_upper in normD:
        #             sex = normD[sex_upper]
             
        #     if relevance is None:
        #          relevance = 'NA'
        #     tmp_table.append([study_id, relevance, observation, parameter, sex, dose])

        # tmp_df = pd.DataFrame(tmp_table, columns=['study_id', 'relevance',
        #                 'observation_normalised', 'organ_normalised',
        #                 'normalised_sex', 'dose'])
        # tmp_df['endpoint_type'] = 'Urinalysis findings'
        # find_df = pd.concat[find_df, tmp_df]

        con.close()

    if args.treatment_related:
        find_df = find_df[find_df.relevance == 'treatment related']

    return study_df, find_df

def filter_study(args,study_df):
    """
    """
    df = study_df[:]

    # Exposure
    if args.min_exposure is not None and args.max_exposure is not None:
        # An exposure range filter is defined
        df = df[df.exposure_period_days >= args.min_exposure &
                df.exposure_period_days <= args.max_exposure]
    elif args.min_exposure is not None:
        # Only a.upper bound for exposure range has been set
        df = df[df.exposure_period_days >= args.min_exposure]
    elif args.max_exposure is not None:
        df = df[df.exposure_period_days <= args.max_exposure]

    # Administration route
    if args.route:
        df = df[df.normalised_administration_route.str.lower().isin([x.lower() for x in args.route])]
        
    # Species
    if args.species:
        df = df[df.normalised_species.str.lower().isin([x.lower() for x in args.species])]
    
    return df

def expand(df,args):

    """
    Expand standardized observation and normalized organs based on
    the hierarchy of ontologies stored in onto_df
    """
       
    #########
    # ORGAN #
    #########
    organs_dict={}
    all_organs=set()
    onto_anatomy=onto_df[(onto_df.ontology == 'anatomy')]

     # get for each organ get all its childs and crate a dict
    for organ in args.organ: 
        all_organs.union([organ])
        related_organs = onto_anatomy[(onto_anatomy.parent_term == organ)]
        all_organs = all_organs.union(related_organs.child_term)
        organs_dict.update({n: organ for n in related_organs.child_term})

    df = df[df['organ_normalised'].isin(all_organs)]
    df.loc[:,'organ_normalised'] = df['organ_normalised'].map(organs_dict)
   
    ###############
    # OBSERVATION #
    ###############
    if args.observation is None:
      
        onto_histopatho=onto_df[(onto_df['ontology'] == 'histopathology') 
                    & (onto_df['parent_term']!='morphologic change')]

        findings_out = pd.merge(df, onto_histopatho, how='left',
                                left_on='observation_normalised', 
                                right_on='child_term')
        findings_out = findings_out[['study_id','relevance','parent_term',
                                    'organ_normalised','normalised_sex',
                                    'dose','subst_id','report_number']]
        findings_out.columns = df.columns
        findings_out.drop_duplicates(inplace=True)
    
    else:
        observation_dict={}
        all_observations=set()      
        onto_histopatho=onto_df[(onto_df.ontology == 'histopathology')]

        # get for each observation all its childs and crate a dict
        for observation in args.observation: 
            all_observations.union([observation])
            related_observation = onto_histopatho[(onto_histopatho.parent_term == observation)]
            all_observations = all_observations.union(related_observation.child_term)
            observation_dict.update({n: observation for n in related_observation.child_term})

        findings_out=df[df['observation_normalised'].isin(all_observations)]
        findings_out.loc[:,'observation_normalised']=df['observation_normalised'].map(observation_dict)
            
    return findings_out

def get_stats(group):
    return {'min': group.min(), 'max': group.max()}

def run(args):

    """
    Run the data extraction based on the parsed filters and expanding
    based on the organs and morphological changes ontologies.
    """

    sys.stdout.write('\nLoading background information for version %s\n' %args.version)
    study_df, find_df = load_version(args)
    
    #################################
    # Select only relevant findings #
    #################################
    sys.stdout.write('Filtering to relevant information\n')
    relevant_studies_df = filter_study(args,study_df)
    relevant_find = find_df[find_df.study_id.isin(relevant_studies_df.study_id)]
    relevant_find = pd.merge(relevant_find, study_df[['study_id', 'subst_id', 'report_number']],
                        how='left', on='study_id', left_index=False,
                        right_index=False, sort=False)
    relevant_find.report_number = relevant_find.report_number.fillna('NA')

    # Findings' level sex filtering
    if args.sex:
        relevant_find = relevant_find[relevant_find.normalised_sex.str.lower() == args.sex.lower()]
    
    start=time.time()
    ###################################
    # Get stats for relevant findings #
    ###################################
    group_df = relevant_find.groupby(('subst_id'))
    # Get the number of studies per substance
    count_df = group_df.study_id.nunique().to_frame().reset_index()
    # Get the list of sudies IDs
    studies_list_df = group_df.report_number.apply(lambda x: '; '.join(set(x))).reset_index()
    # Get the global dose range per substance
    range_df = relevant_find[relevant_find.dose > 0]
    range_df = range_df.groupby(('subst_id')).dose.apply(get_stats).unstack().reset_index()
    # Get all stats into a single dataframe
    stats_df = pd.merge(count_df, range_df, how='inner', on='subst_id', 
                        left_index=False, right_index=False, sort=False)
    stats_df = pd.merge(stats_df, studies_list_df, how='left', on='subst_id', 
                        left_index=False, right_index=False, sort=False)
    stats_df.columns = ['subst_id', 'study_count', 'dose_max', 'dose_min', 
                        'report_number_list']

    ###################################################################
    # Expand based on anatomical and morphological changes ontologies #
    ###################################################################
    # Expand organs and histopathological findings according to the ontologies 
    # and filter by finding-based arguments
    sys.stdout.write('Expand based on anatomic and morphological change ontologies\n')
    filtered_find = expand(relevant_find,args)

    if filtered_find.empty:
        raise Exception('Filtered out all rows, so the dataframe is empty.')

    ######################################
    # Aggragate by substance and finding #
    ######################################
    # Define finding as organ+observation
    filtered_find.fillna(value={'organ_normalised': 'NA', 'observation_normalised': 'NA'}, inplace=True)
    filtered_find['finding'] = filtered_find.apply(lambda row: row.organ_normalised+'_'+row.observation_normalised, axis=1)
    filtered_find = filtered_find[['subst_id', 'finding', 'dose']]

    # Aggregate by substance and finding (as defined above), 
    # keeping the minimum dose for each substance/finding instance
    group_df = filtered_find.groupby(('subst_id', 'finding')).min().add_prefix('min_').reset_index()
    
    #######################################
    # Pivot so that each finding is a row #
    #######################################
    ### Quantitative
    pivotted_df = group_df.pivot_table(index='subst_id', columns='finding', values='min_dose').reset_index()
    pivotted_df['is_active'] = 'True'
    quantitative_df = pd.merge(stats_df, pivotted_df, how='left', on='subst_id', 
                                left_index=False, right_index=False, sort=False)
    quantitative_df.is_active = quantitative_df.is_active.fillna('False')
    # Reorder columns
    cols = quantitative_df.columns.tolist()
    cols = cols[0:5]+[cols[-1]]+cols[5:-1]
    quantitative_df = quantitative_df[cols]
    
    ### Qualitative
    group_df.loc[:,'min_dose'] = 1
    pivotted_df = group_df.pivot_table(index='subst_id', columns='finding', values='min_dose').reset_index()
    pivotted_df['is_active'] = 'True'
    qualitative_df = pd.merge(stats_df, pivotted_df, how='left', on='subst_id',
                                left_index=False, right_index=False, sort=False)
    qualitative_df.is_active = qualitative_df.is_active.fillna('False')
    # Reorder columns
    cols = qualitative_df.columns.tolist()
    cols = cols[0:5]+[cols[-1]]+cols[5:-1]
    qualitative_df = qualitative_df[cols]

    end=time.time()

    print ("Time: "+str(end-start))
    ####################
    # Save the results #
    ####################
    quantitative_df.to_csv(args.output_basename+'_quant.tsv', 
                            sep='\t', index=False)
    qualitative_df.to_csv(args.output_basename+'_qual.tsv', 
                            sep='\t', index=False)

def main ():
    """
    Parse arguments and load the extraction filters.
    """
    parser = argparse.ArgumentParser(description='Exract studies\' \
            findings based on the given filtering and the organs\' and \
            morphological changes\' ontologies-based expansions of these \
            findngs.')

    # Version-related arguments
    parser.add_argument('-v', '--version', help='Vitic database version \
            (default: oracle).', 
            choices=['local', 'oracle'], default= 'oracle', required=False)
    parser.add_argument('-n', '--host', help='If working with Vitic\'s \
            Oracle database, provide the Oracle host\'s.', 
            required=False)
    parser.add_argument('-d', '--sid', help='If working with Vitic\'s \
            Oracle database, provide the Oracle SID\'s.', 
            required=False)
    parser.add_argument('-u', '--user', help='If working with Vitic\'s \
            Oracle database, provide the Oracle database \
            user name.', required=False)
    parser.add_argument('-p', '--passw', help='If working with Vitic\'s \
            Oracle database, provide the Oracle database \
            password.',  required=False)
    parser.add_argument('-c', '--port', help='If working with Vitic\'s \
            Oracle database, provide the Oracle database \
            port (default: 1521).',  default='1521', required=False)

    # Study-related arguments
    parser.add_argument('-i', '--min_exposure', help='Minimum exposure \
            period (days).', required=False)
    parser.add_argument('-e', '--max_exposure', help='Maximum exposure \
            period (days).', required=False)
    parser.add_argument('-r', '--route', help='Administration route. You can filter for \
            more than one administration route by passing a blank space-separated list.', 
            choices=['cutaneous', 'dietary', 'oral', 'oral gavage', 
            'intragastric', 'nasogastric', 'oropharyngeal', 'endotracheal', 
            'intra-articular', 'intradermal', 'intraesophageal', 
            'intraileal', 'intramuscular', 'subcutaneous', 'intraocular', 
            'intraperitoneal', 'intrathecal', 'intrauterine', 
            'intravenous', 'intravenous bolus', 'intravenous drip', 
            'parenteral', 'nasal', 'respiratory (inhalation)', 
            'percutaneous', 'rectal', 'vaginal', 'subarachnoid'], 
            type= str.lower,
            # nargs='*' is used to allow to pass a list (separated by 
            # blank spaces) as the argument 
            # '*' -> 0 or more
            # '+' -> 1 or more
            nargs='*', required=False)
    parser.add_argument('-s', '--species', help='Species. You can filter for \
            more than one species by passing a blank space-separated list.', 
            choices=['mouse', 'rat', 'hamster', 'guinea pig', 'rabbit', 'dog', 
            'pig', 'marmoset', 'monkey', 'baboon'], type= str.lower,
            nargs='*', required=False)

    # Finding-related arguments
    parser.add_argument('-a', '--organ', help='Anatomical entity that the \
            finding refers to. You can filter for more than one organ by passing \
            a blank space-separated list.', type= str.lower,
            nargs='*', required=True)
    parser.add_argument('-m', '--observation', help='Morphological change \
            type that the finding refers to. You can filter for more than one \
            morphological change by passing a blank space-separated list.', type= str.lower,
            nargs='*', required=False)
    parser.add_argument('-t', '--treatment_related', help='Keep only treatment-related \
            findings.', action='store_true', default= False,
            required=False)
    parser.add_argument('-x', '--sex', help='Finding\'s sex.', 
            choices=['F', 'M', 'Both'], required=False)
    
    # Output file base name
    parser.add_argument('-o', '--output_basename', help='Output file base name. Two output \
            files will be generated: basename_quant.tsv and basename_qual.tsv, with \
            quantitative and qualitative results respectively. (default: output).', 
            default= 'output', required=False)

    args = parser.parse_args()
    if args.version == 'oracle' and (args.host is None or args.passw is None or 
                                    args.sid is None or args.user is None):
       raise argparse.ArgumentTypeError('Oracle credentials required to connect to the Oracle database.')

    if args.observation:
        right_case_observations = []
        for obs in args.observation:
            right_case_obs =  list(onto_df[onto_df['parent_term'].str.lower() == obs].parent_term.unique())
            if len(right_case_obs) == 0:
                sys.stderr.write('The observation %s is not found in the database.\n' %obs)
            else:
                right_case_observations.extend(right_case_obs)
        if len(right_case_observations) == 0:
            raise argparse.ArgumentTypeError('None of the observations you are trying to filter for are found: %s.' %args.observation)
        args.observation = right_case_observations

    right_case_organs = []
    for org in args.organ:
        right_case_obs =  list(onto_df[onto_df['parent_term'].str.lower() == org].parent_term.unique())
        if len(right_case_obs) == 0:
            sys.stderr.write('The organ %s is not found in the database.\n' %org)
        else:
            right_case_organs.extend(right_case_obs)
    if len(right_case_organs) == 0:
        raise argparse.ArgumentTypeError('None of the organs you are trying to filter for are found: %s.' %args.organ)
    args.organ = right_case_organs

    run(args)

if __name__ == '__main__':    
    main()
